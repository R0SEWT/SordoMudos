{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import import_ipynb\n",
    "import model \n",
    "import data_processing  \n",
    "import data_preprocessing  \n",
    "\n",
    "\n",
    "process_imgs = data_processing.process_imgs\n",
    "process_and_save_silhouette = data_preprocessing.process_and_save_silhouette\n",
    "get_model = model.get_model\n",
    "RusticModel = model.RusticModel\n",
    "ViTModel = model.ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"./logs/data_validation.log\",  # Nombre del archivo de log\n",
    "    filemode=\"a\",  # Modo de apertura en append para no sobrescribir\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo (GPU o CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Usando dispositivo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(data_directory):\n",
    "    X_train, X_val, y_train, y_val, label_mapping = process_imgs(data_directory, dir)\n",
    "    return X_train, X_val, y_train, y_val, label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(X, y):\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    if X.dim() == 3:\n",
    "        X = X.unsqueeze(1)\n",
    "    else:\n",
    "        X = X.permute(0, 3, 1, 2)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define la ruta del directorio de datos\n",
    "data_directory = \"/home/rosewt/Documentos/codigos2024/SordoMudos/datasets/Static-Hand-Gestures-of-the-Peruvian-Sign-Language-Alphabet\"\n",
    "\n",
    "# Cargar y procesar los datos\n",
    "X_train, X_val, y_train, y_val, label_mapping = load_and_process_data(data_directory)\n",
    "\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"gray\")\n",
    "\n",
    "# Convertir los datos de validación a tensores\n",
    "X_val, y_val = convert_to_tensors(X_val, y_val)\n",
    "\n",
    "# Información sobre el conjunto de validación\n",
    "logging.info(f\"Tamaño del conjunto de validación: {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15896/3820318020.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar el modelo y número de clases\n",
    "num_classes = len(label_mapping)\n",
    "model = RusticModel(num_classes).to(device)\n",
    "# Alternativa: model = ViTModel(num_classes).to(device)\n",
    "\n",
    "# Cargar los pesos del modelo entrenado\n",
    "model_path = \"rustic.pth\"  # Ruta de tu modelo entrenado\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "logging.info(f\"Modelo cargado exitosamente desde {model_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluar el modelo\n",
    "val_loss = 0\n",
    "val_correct = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val)):\n",
    "        images = X_val[i].unsqueeze(0).to(device)  # Agregar dimensión batch\n",
    "        labels = y_val[i].unsqueeze(0).to(device)\n",
    "\n",
    "        # Redimensionar las imágenes a 224x224\n",
    "        images = nn.functional.interpolate(images, size=(224, 224))\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Acumulación de la pérdida y precisión\n",
    "        val_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calcular la pérdida y precisión de validación\n",
    "val_loss /= len(X_val)\n",
    "val_accuracy = val_correct / len(X_val)\n",
    "logging.info(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todas las predicciones y etiquetas verdaderas para el conjunto de validación\n",
    "def get_predictions_and_labels(model, X_val, y_val):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X_val)):\n",
    "            images = X_val[i].unsqueeze(0).to(device)  # Añadir dimensión batch\n",
    "            labels = y_val[i].unsqueeze(0).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Guardar predicciones y etiquetas\n",
    "            all_preds.append(predicted.item())\n",
    "            all_labels.append(labels.item())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x36864 and 50176x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Obtener las predicciones y etiquetas verdaderas\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_val\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mget_predictions_and_labels\u001b[0;34m(model, X_val, y_val)\u001b[0m\n\u001b[1;32m     10\u001b[0m labels \u001b[38;5;241m=\u001b[39m y_val[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Guardar predicciones y etiquetas\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m<string>:38\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x36864 and 50176x256)"
     ]
    }
   ],
   "source": [
    "# Obtener las predicciones y etiquetas verdaderas\n",
    "y_true, y_pred = get_predictions_and_labels(model, X_val, y_val)\n",
    "\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_mapping.keys())\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas unitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import data_preprocessing  \n",
    "import cv2\n",
    "\n",
    "binarize_with_canny = data_preprocessing.binarize_with_canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_image(model, val, predict):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():    \n",
    "        image = val.unsqueeze(0).to(device)  # Añadir dimensión batch\n",
    "        labels = predict.unsqueeze(0).to(device)\n",
    "        # Forward pass\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        # Guardar predicciones y etiquetas\n",
    "        v = labels.item()\n",
    "        p = predicted.item()\n",
    "\n",
    "    return v, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    \"\"\"\n",
    "    Carga y preprocesa una sola imagen para pasarla por el modelo.\n",
    "    \"\"\"\n",
    "    # Definir las transformaciones necesarias\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convertir a escala de grises\n",
    "        transforms.Resize((224, 224)),               # Redimensionar a 224x224\n",
    "        transforms.ToTensor(),                       # Convertir a tensor\n",
    "        transforms.Normalize((0.5,), (0.5,))         # Normalizar (ajusta según el entrenamiento)\n",
    "    ])\n",
    "\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    #image = binarize_with_canny(image)\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    \n",
    "    # Aplicar transformaciones\n",
    "    image = transform(image)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Agregar una dimensión para el batch\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_tensor, label_mapping):\n",
    "    \"\"\"\n",
    "    Realiza una predicción para una sola imagen.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Pasar la imagen por el modelo\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        output = model(image_tensor)\n",
    "        \n",
    "        # Obtener la predicción\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        predicted_label = predicted.item()\n",
    "        \n",
    "        # Mapear el índice a la etiqueta correspondiente\n",
    "        label_name = list(label_mapping.keys())[list(label_mapping.values()).index(predicted_label)]\n",
    "        \n",
    "    return label_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(imgs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(imgs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 20\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     23\u001b[0m label_to_index \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m9\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m11\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m12\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m13\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m14\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m15\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m16\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m17\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m18\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m19\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m21\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m22\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m23\u001b[39m}\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Ruta de la imagen de prueba\n",
    "\n",
    "test_image_path = './augmented_images/a/a (3)_original.jpg'\n",
    "test_image_path = './augmented_images/s/s (3)_original.jpg'\n",
    "\n",
    "\n",
    "\n",
    "import data_processing\n",
    "process_imgs = data_processing.process_imgs\n",
    "preprocess = data_processing.preprocess\n",
    "\n",
    "test_path = \"/home/rosewt/Documentos/codigos2024/SordoMudos/src/notebooks/test\"\n",
    "\n",
    "\n",
    "imgs = preprocess(test_path, output_dir='test_augmented')\n",
    "\n",
    "print(type(imgs[0]))\n",
    "print(len(imgs[0]))\n",
    "\n",
    "plt.imshow(imgs[0][4], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "label_to_index = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'k': 9, 'l': 10, 'm': 11, 'n': 12, 'o': 13, 'p': 14, 'q': 15, 'r': 16, 's': 17, 't': 18, 'u': 19, 'v': 20, 'w': 21, 'x': 22, 'y': 23}\n",
    "\n",
    "\n",
    "y_val = ['a'] * len(imgs)\n",
    "\n",
    "\n",
    "imgs_resized = imgs\n",
    "\n",
    "#print(len(imgs_resized))\n",
    "\n",
    "#X_val = torch.tensor(imgs_resized, dtype=torch.float32).unsqueeze(1)  # Añade dimensión de canal\n",
    "#y_val = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31659/438072132.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 224 at dim 2 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convertir los datos de validación a tensores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Seleccionar el modelo y número de clases\u001b[39;00m\n\u001b[1;32m      6\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_mapping)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mconvert_to_tensors\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensors\u001b[39m(X, y):\n\u001b[0;32m----> 2\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m      4\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 224 at dim 2 (got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convertir los datos de validación a tensores\n",
    "X_val, y_val = convert_to_tensors(imgs, y_val)\n",
    "\n",
    "\n",
    "# Seleccionar el modelo y número de clases\n",
    "num_classes = len(label_mapping)\n",
    "model = RusticModel(num_classes).to(device)\n",
    "# Alternativa: model = ViTModel(num_classes).to(device)\n",
    "\n",
    "# Cargar los pesos del modelo entrenado\n",
    "model_path = \"rustic.pth\"  # Ruta de tu modelo entrenado\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "logging.info(f\"Modelo cargado exitosamente desde {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluar el modelo\n",
    "val_loss = 0\n",
    "val_correct = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_val)):\n",
    "        images = X_val[i].unsqueeze(0).to(device)  # Agregar dimensión batch\n",
    "        labels = y_val[i].unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Acumulación de la pérdida y precisión\n",
    "        val_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calcular la pérdida y precisión de validación\n",
    "val_loss /= len(X_val)\n",
    "val_accuracy = val_correct / len(X_val)\n",
    "logging.info(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
